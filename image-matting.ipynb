{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from skimage import io\n",
    "from os.path import sep, join\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from model.basnet import BASNet\n",
    "from data_loader import SalObjDataset, RescaleT, ToTensorLab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task-4 基于BASNet的抠图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其实Task-2已经完成这个项目的绝大部分内容了，只需要稍微调整一下保存函数，添加一个mask就可以了。\n",
    "所以只需要添加以下代码：\n",
    "```python\n",
    "def save_matting_output(image_path: str, pred, output_dir=join(\".\", \"output\")):\n",
    "    ...\n",
    "\n",
    "    mask = np.array(img.convert('L'))\n",
    "    masked = np.dstack((original_image, mask))\n",
    "    masked_img = Image.fromarray(masked, 'RGBA')\n",
    "\n",
    "    ...\n",
    "```\n",
    "这样就好啦~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(tensor):\n",
    "    max_val = torch.max(tensor)\n",
    "    min_val = torch.min(tensor)\n",
    "    return (tensor - min_val) / (max_val - min_val)\n",
    "\n",
    "def save_matting_output(image_path: str, pred, output_dir=join(\".\", \"output\")):\n",
    "    if os.path.exists(output_dir) is False:\n",
    "        os.mkdir(output_dir)\n",
    "    \n",
    "    pred = pred.squeeze()\n",
    "    pred = pred.cpu().data.numpy()\n",
    "\n",
    "    img = Image.fromarray(pred * 255).convert('RGB')\n",
    "    image_name = image_path.split(sep)[-1]\n",
    "    original_image = io.imread(image_path)\n",
    "    img = img.resize((original_image.shape[1], original_image.shape[0]), \n",
    "                     Image.BILINEAR)\n",
    "    \n",
    "    mask = np.array(img.convert('L'))\n",
    "    masked = np.dstack((original_image, mask))\n",
    "    masked_img = Image.fromarray(masked, 'RGBA')\n",
    "\n",
    "    filename = '.'.join(image_name.split('.')[:-1])\n",
    "    masked_img.save(join(output_dir, filename + '_matting.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = join('.', 'test', 'img-matting')\n",
    "pred_dir = join('.', 'test', 'img-matting', 'outputs')\n",
    "model_dir = join('.', 'saved_models', 'basnet_bsi', 'basnet.pth')\n",
    "\n",
    "img_path_list = glob.glob(join(img_dir, '*.jpg'))\n",
    "\n",
    "test_salobj_dataset = SalObjDataset(img_name_list = img_path_list, \n",
    "                                    lbl_name_list = [],\n",
    "                                    transform = transforms.Compose([\n",
    "                                        RescaleT(256),\n",
    "                                        ToTensorLab(flag=0)\n",
    "                                    ]))\n",
    "test_salobj_dataloader = DataLoader(test_salobj_dataset, batch_size=1, \n",
    "                                    shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Loading BASNet...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jerry\\miniconda3\\envs\\vpteam\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Jerry\\miniconda3\\envs\\vpteam\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference on image 1\n",
      "Image Name: alpaca.jpg\n",
      "Inference on image 2\n",
      "Image Name: cat.jpg\n",
      "Inference on image 3\n",
      "Image Name: character-C.jpg\n"
     ]
    }
   ],
   "source": [
    "print(\"...Loading BASNet...\")\n",
    "net = BASNet(3, 1)\n",
    "net.load_state_dict(torch.load(model_dir))\n",
    "if torch.cuda.is_available():\n",
    "    net.cuda()\n",
    "net.eval()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for i, data in enumerate(test_salobj_dataloader):\n",
    "        print(f\"Inference on image {i+1}\")\n",
    "        print(f\"Image Name: {img_path_list[i].split(sep)[-1]}\")\n",
    "        \n",
    "        inputs = data['image']\n",
    "        inputs = inputs.type(torch.FloatTensor)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            inputs = Variable(inputs.cuda())\n",
    "        else:\n",
    "            inputs = Variable(inputs)\n",
    "        \n",
    "        d1, *_ = net(inputs)\n",
    "\n",
    "        pred = d1[:, 0, :, :]\n",
    "        pred = normalize(pred)\n",
    "\n",
    "        save_matting_output(img_path_list[i], pred, pred_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vpteam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
